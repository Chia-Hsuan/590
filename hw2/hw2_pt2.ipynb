{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "# Importing core neural networks layers \n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "# Importing CNN layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "# Importing the sequential model in Keras\n",
    "# Used as a linear stack of nn layers\n",
    "from keras.models import Sequential, Model\n",
    "# Tools for data transformation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.applications import VGG16\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Image Classification\n",
    "We’ll continue to use the Fashion MNIST dataset and build a deep convolutional network for classification.\n",
    "## 2.1 Deep CNN\n",
    "Build a deep CNN to classify the images. Provide a brief description of the architectural choices you’ve made: kernel sizes, strides, padding, network depth. Train your network end-to-end. Report on your model’s performance on training set and test set.\n",
    "## 2.2 Transfer Learning\n",
    "Repeat the same task, but this time utilize a pre-trained network for the major- ity of your model. You should only train the final Dense layer, all other weights should be fixed. You can use whichever pre-trained backbone you like (ResNet, VGG, etc). Report on your model’s performance on training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Deep CNN\n",
    "\n",
    "# Data Munging/Reshaping\n",
    "# Load pre-shuffled Fashion MNIST data into train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# Declaring a depth of 1 for MNIST\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28,1)\n",
    "# Setting up calues as float32s that are bounded between 0 and 1\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 24, 24, 32)        9248      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 4608)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                294976    \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 305,194\n",
      "Trainable params: 305,194\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Declaring sequential model\n",
    "model = Sequential()\n",
    "# CNN input layer: input_shape: (depth,width,height)\n",
    "# CNN convolution: number of filters, height and width of kernel\n",
    "model.add(Conv2D(filters = 32,kernel_size=(3, 3), \n",
    "                 activation='relu', strides=(1, 1), \n",
    "                 padding='valid',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters = 32,kernel_size=(3, 3), \n",
    "                 activation='relu', strides=(1, 1), \n",
    "                 padding='valid', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "# Setting up the fully connected lauer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.6488 - acc: 0.7746 - val_loss: 0.3927 - val_acc: 0.8603\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 94s 2ms/step - loss: 0.4289 - acc: 0.8495 - val_loss: 0.3302 - val_acc: 0.8828\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 94s 2ms/step - loss: 0.3757 - acc: 0.8668 - val_loss: 0.3015 - val_acc: 0.8942\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 91s 2ms/step - loss: 0.3434 - acc: 0.8761 - val_loss: 0.2869 - val_acc: 0.8994\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 93s 2ms/step - loss: 0.3203 - acc: 0.8861 - val_loss: 0.2642 - val_acc: 0.9035\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.3004 - acc: 0.8933 - val_loss: 0.2504 - val_acc: 0.9091\n",
      "Epoch 7/100\n",
      "60000/60000 [==============================] - 93s 2ms/step - loss: 0.2874 - acc: 0.8967 - val_loss: 0.2448 - val_acc: 0.9130\n",
      "Epoch 8/100\n",
      "60000/60000 [==============================] - 91s 2ms/step - loss: 0.2696 - acc: 0.9003 - val_loss: 0.2392 - val_acc: 0.9142\n",
      "Epoch 9/100\n",
      "60000/60000 [==============================] - 91s 2ms/step - loss: 0.2608 - acc: 0.9044 - val_loss: 0.2370 - val_acc: 0.9165\n",
      "Epoch 10/100\n",
      "60000/60000 [==============================] - 92s 2ms/step - loss: 0.2492 - acc: 0.9071 - val_loss: 0.2358 - val_acc: 0.9170\n",
      "Epoch 11/100\n",
      "60000/60000 [==============================] - 93s 2ms/step - loss: 0.2424 - acc: 0.9115 - val_loss: 0.2279 - val_acc: 0.9178\n",
      "Epoch 12/100\n",
      "60000/60000 [==============================] - 95s 2ms/step - loss: 0.2329 - acc: 0.9149 - val_loss: 0.2322 - val_acc: 0.9173\n",
      "Epoch 13/100\n",
      "60000/60000 [==============================] - 103s 2ms/step - loss: 0.2304 - acc: 0.9146 - val_loss: 0.2302 - val_acc: 0.9197\n",
      "Epoch 14/100\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.2192 - acc: 0.9187 - val_loss: 0.2265 - val_acc: 0.9192\n",
      "Epoch 15/100\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.2144 - acc: 0.9203 - val_loss: 0.2236 - val_acc: 0.9211\n",
      "Epoch 16/100\n",
      "60000/60000 [==============================] - 69s 1ms/step - loss: 0.2091 - acc: 0.9205 - val_loss: 0.2238 - val_acc: 0.9194\n",
      "Epoch 17/100\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.2048 - acc: 0.9235 - val_loss: 0.2226 - val_acc: 0.9237\n",
      "Epoch 18/100\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1998 - acc: 0.9254 - val_loss: 0.2270 - val_acc: 0.9212\n",
      "Epoch 19/100\n",
      "60000/60000 [==============================] - 65s 1ms/step - loss: 0.1914 - acc: 0.9277 - val_loss: 0.2240 - val_acc: 0.9214\n",
      "Epoch 20/100\n",
      "60000/60000 [==============================] - 61s 1ms/step - loss: 0.1922 - acc: 0.9276 - val_loss: 0.2251 - val_acc: 0.9250\n",
      "Epoch 21/100\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1851 - acc: 0.9304 - val_loss: 0.2345 - val_acc: 0.9172\n",
      "Epoch 22/100\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1843 - acc: 0.9302 - val_loss: 0.2228 - val_acc: 0.9257\n",
      "Epoch 23/100\n",
      "60000/60000 [==============================] - 64s 1ms/step - loss: 0.1787 - acc: 0.9326 - val_loss: 0.2270 - val_acc: 0.9229\n",
      "Epoch 24/100\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1749 - acc: 0.9337 - val_loss: 0.2213 - val_acc: 0.9265\n",
      "Epoch 25/100\n",
      "60000/60000 [==============================] - 62s 1ms/step - loss: 0.1724 - acc: 0.9344 - val_loss: 0.2265 - val_acc: 0.9253\n",
      "Epoch 26/100\n",
      "60000/60000 [==============================] - 63s 1ms/step - loss: 0.1711 - acc: 0.9345 - val_loss: 0.2247 - val_acc: 0.9228\n",
      "Epoch 27/100\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.1671 - acc: 0.9343 - val_loss: 0.2344 - val_acc: 0.9231\n",
      "Epoch 28/100\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.1629 - acc: 0.9377 - val_loss: 0.2309 - val_acc: 0.9253\n",
      "Epoch 29/100\n",
      "60000/60000 [==============================] - 66s 1ms/step - loss: 0.1633 - acc: 0.9373 - val_loss: 0.2276 - val_acc: 0.9248\n",
      "Epoch 30/100\n",
      "60000/60000 [==============================] - 68s 1ms/step - loss: 0.1605 - acc: 0.9382 - val_loss: 0.2467 - val_acc: 0.9225\n",
      "Epoch 31/100\n",
      "60000/60000 [==============================] - 67s 1ms/step - loss: 0.1583 - acc: 0.9390 - val_loss: 0.2407 - val_acc: 0.9231\n",
      "Epoch 00031: early stopping\n"
     ]
    }
   ],
   "source": [
    "#  Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# Fitting the model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=128,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 3s 252us/step\n",
      "[0.24069012755155564, 0.9231]\n"
     ]
    }
   ],
   "source": [
    "#  Evaluating the model\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1,len(loss) + 1)\n",
    "plt.plot( epochs, loss, 'r', label = 'Training Loss')\n",
    "plt.plot( epochs, val_loss, 'b', label = 'Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Transfer Learning\n",
    "# Data Munging/Reshaping\n",
    "# Load pre-shuffled Fashion MNIST data into train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# Declaring a depth of 1 for MNIST\n",
    "x_train = x_train.reshape(x_train.shape[0], 784)\n",
    "x_test = x_test.reshape(x_test.shape[0], 784)\n",
    "# Setting up calues as float32s that are bounded between 0 and 1\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = np.dstack([x_train] * 3)\n",
    "x_test = np.dstack([x_test] * 3)\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 3)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 3)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in x_train])\n",
    "x_test = np.asarray([img_to_array(array_to_img(im, scale=False).resize((48,48))) for im in x_test])\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10240/60000 [====>.........................] - ETA: 8:05"
     ]
    }
   ],
   "source": [
    "# Transfer Learning with VGG backbone\n",
    "conv_base = VGG16(weights=\"imagenet\",\n",
    "                  include_top=False,\n",
    "                  input_shape=(48,48,3))\n",
    "# Extract features\n",
    "train_features = conv_base.predict(np.array(x_train), batch_size=16, verbose=1)\n",
    "test_features = conv_base.predict(np.array(x_test), batch_size=16, verbose=1)\n",
    "\n",
    "# Build a model\n",
    "model = Sequential()\n",
    "model.add(conv_base)\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dense(10, activation=\"sigmoid\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freezing the weights for transfer learning\n",
    "conv_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'dense_13/kernel:0' shape=(512, 256) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_13/bias:0' shape=(256,) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_14/kernel:0' shape=(256, 10) dtype=float32_ref>,\n",
       " <tf.Variable 'dense_14/bias:0' shape=(10,) dtype=float32_ref>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.trainable_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      " 4736/60000 [=>............................] - ETA: 10:00 - loss: 0.5529 - acc: 0.7480"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-ffc0242aa49c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m                     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m                     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                     callbacks=[EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto')])\n\u001b[0m",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/keras/engine/training.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/keras/engine/training_arrays.pyc\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/keras/backend/tensorflow_backend.pyc\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda2/lib/python2.7/site-packages/tensorflow/python/client/session.pyc\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1380\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1381\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1382\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1383\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1384\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Compile the model\n",
    "model.compile(loss=\"binary_crossentropy\", \n",
    "              optimizer=RMSprop(1e-4),\n",
    "              metrics=[\"acc\"])\n",
    "# Train the model\n",
    "history = model.fit(np.reshape(train_features, (60000, 1*1*512)), \n",
    "                    y_train,\n",
    "                    epochs=100,\n",
    "                    batch_size=128,\n",
    "                    shuffle=True,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Evaluating the model\n",
    "score = model.evaluate(np.reshape(test_features, (10000, 1*1*512)), y_test, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "# Training + Valdiation Accuracy\n",
    "epochs = range(1,len(acc) + 1)\n",
    "plt.plot( epochs, acc, 'r', label = 'Training Accuracy')\n",
    "plt.plot( epochs, val_acc, 'b', label = 'Validation Accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "\n",
    "# Training + Validation Loss\n",
    "epochs = range(1,len(loss) + 1)\n",
    "plt.plot( epochs, loss, 'r', label = 'Training Loss')\n",
    "plt.plot( epochs, val_loss, 'b', label = 'Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
