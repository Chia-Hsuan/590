{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# modules\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import fashion_mnist\n",
    "# Importing core neural networks layers \n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, UpSampling2D\n",
    "# Importing CNN layers\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input\n",
    "# Importing the sequential model in Keras\n",
    "# Used as a linear stack of nn layers\n",
    "from keras.models import Sequential, Model\n",
    "# Tools for data transformation\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Autoencoder\n",
    "\n",
    "A convolutional autoencoder is a particular flavor of autoencoder where we use convolutional layers instead of dense layers. We have previously applied autoencoders to images using only Dense layers and the result worked fairly well. However, the local spatial correlations of images imply that we should be able to do better using convolutional layers instead of Dense layers.<br/>&nbsp;&nbsp;Build and fit a convolutional autoencoder for the Fashion MNIST dataset. The components of this network will be many of the same pieces we’ve used with convolutional classification networks: Conv2D, MaxPooling, and so on. The encoder part of the network should run the input image through a few convolutional layers of your choice. The decoder part of the network will utilize UpSampling2D to get the representation back to the original image size.<br/>&nbsp;&nbsp;An example to guide your thinking can be found toward the bottom of this post https://blog.keras.io/building-autoencoders-in-keras.html.<br/>&nbsp;&nbsp;After training your network, visualize some examples of input images and their decoded reconstruction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Munging/Reshaping\n",
    "# Load pre-shuffled Fashion MNIST data into train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# Declaring a depth of 1 for MNIST\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28,1)\n",
    "# Setting up calues as float32s that are bounded between 0 and 1\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_img = Input(shape=(28, 28, 1))\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\n",
    "x = MaxPooling2D((2, 2), padding='same')(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling2D((2, 2), padding='same')(x)\n",
    "\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "x = UpSampling2D((2, 2))(x)\n",
    "decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n",
    "\n",
    "autoencoder = Model(input_img, decoded)\n",
    "autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/100\n",
      "60000/60000 [==============================] - 83s 1ms/step - loss: 0.3208 - val_loss: 0.2918\n",
      "Epoch 2/100\n",
      "60000/60000 [==============================] - 82s 1ms/step - loss: 0.2835 - val_loss: 0.2832\n",
      "Epoch 3/100\n",
      "60000/60000 [==============================] - 83s 1ms/step - loss: 0.2764 - val_loss: 0.2752\n",
      "Epoch 4/100\n",
      "60000/60000 [==============================] - 91s 2ms/step - loss: 0.2725 - val_loss: 0.2724\n",
      "Epoch 5/100\n",
      "60000/60000 [==============================] - 94s 2ms/step - loss: 0.2705 - val_loss: 0.2727\n",
      "Epoch 6/100\n",
      "60000/60000 [==============================] - 79s 1ms/step - loss: 0.2683 - val_loss: 0.2748\n",
      "Epoch 7/100\n",
      "26624/60000 [============>.................] - ETA: 51s - loss: 0.2674"
     ]
    }
   ],
   "source": [
    "# Train the model for 100 epochs\n",
    "history = autoencoder.fit(x_train, x_train,\n",
    "                epochs=100,\n",
    "                batch_size=128,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_test, x_test),\n",
    "                callbacks=[EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot( epochs, loss, 'r', label = 'Training Loss')\n",
    "plt.plot( epochs, val_loss, 'b', label = 'Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruction\n",
    "n = 5\n",
    "for k in range(n):\n",
    "    ax = plt.subplot(2, n, k+1)\n",
    "    plt.imshow(x_test[k:k+1,:].reshape((28,28)))\n",
    "    ax = plt.subplot(2, n, k+1 + n)\n",
    "    reconstruction = autoencoder.predict(x_test[k:k+1,:])\n",
    "    reconstruction.resize((28,28))\n",
    "    plt.imshow(reconstruction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Image Classification\n",
    "We’ll continue to use the Fashion MNIST dataset and build a deep convolutional network for classification.\n",
    "## 2.1 Deep CNN\n",
    "Build a deep CNN to classify the images. Provide a brief description of the architectural choices you’ve made: kernel sizes, strides, padding, network depth. Train your network end-to-end. Report on your model’s performance on training set and test set.\n",
    "## 2.2 Transfer Learning\n",
    "Repeat the same task, but this time utilize a pre-trained network for the major- ity of your model. You should only train the final Dense layer, all other weights should be fixed. You can use whichever pre-trained backbone you like (ResNet, VGG, etc). Report on your model’s performance on training set and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Deep CNN\n",
    "\n",
    "# Data Munging/Reshaping\n",
    "# Load pre-shuffled Fashion MNIST data into train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "# Declaring a depth of 1 for MNIST\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28,1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28,1)\n",
    "# Setting up calues as float32s that are bounded between 0 and 1\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "# Convert 1-dimensional class arrays to 10-dimensional class matrices\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring sequential model\n",
    "model = Sequential()\n",
    "# CNN input layer: input_shape: (depth,width,height)\n",
    "# CNN convolution: number of filters, height and width of kernel\n",
    "model.add(Conv2D(filters = 32,kernel_size=(3, 3), \n",
    "                 activation='relu', strides=(1, 1), \n",
    "                 padding='valid',\n",
    "                 input_shape=(28,28,1)))\n",
    "model.add(Conv2D(filters = 32,kernel_size=(3, 3), \n",
    "                 activation='relu', strides=(1, 1), \n",
    "                 padding='valid', input_shape=(28,28,1)))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(Dropout(0.25))\n",
    "# Setting up the fully connected lauer\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Compiling the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "# Fitting the model\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=128,\n",
    "                    verbose=0,\n",
    "                    validation_data=(x_test, y_test),\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', min_delta=0, patience=7, verbose=1, mode='auto')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Evaluating the model\n",
    "score = model.evaluate(x_test, y_test, verbose=1)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.plot( epochs, loss, 'r', label = 'Training Loss')\n",
    "plt.plot( epochs, val_loss, 'b', label = 'Validation Loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 Transfer Learning\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
